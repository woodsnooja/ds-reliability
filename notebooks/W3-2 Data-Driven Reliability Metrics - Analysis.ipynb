{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03e3f0f7",
   "metadata": {},
   "source": [
    "# <center> Data-Driven Reliability Metrics - Analysis </center>\n",
    "## <center> Week 3 - Part 2</center>\n",
    "## <center> Interactive Notebook </center>\n",
    "\n",
    "\n",
    "<center>üìö Source: W3-2 Data-Driven Reliability Metrics - Analysis</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d76c365",
   "metadata": {},
   "source": [
    "## Notebook Overview\n",
    "In this brief notebook, we'll use what we have learnt in part 1 of week 3 (*W3-1 Data-Driven Reliability Metrics*) to gain insight into our data using visualisation tools. Instead of developing our data preparation and cleaning processes again, we'll load in scripts that contain what we've previously developed (located in the `./scripts` directory)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0dda95",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [3-2.1 - Analysing the effect of our decisions on reliability measures](#3-2.1)\n",
    "* [3-2.2 - Additional Analysis](#3-2.2)\n",
    "* [Wrap up and homework](#wrap-up)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63924e4",
   "metadata": {},
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29988720",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pandas numpy reliability plotly panel nb_black bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aa0f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b587466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from reliability.Fitters import Fit_Weibull_2P\n",
    "import plotly.express as px\n",
    "\n",
    "import panel as pn\n",
    "import panel.widgets as pnw\n",
    "\n",
    "from bokeh.layouts import gridplot, column\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.models import ColumnDataSource, DataTable, TableColumn, Column, Row, Slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266bdf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import data_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e203baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.extension(\"plotly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8f5fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6908d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package for ensuring code we write is formatted nicely\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccad0d7a",
   "metadata": {},
   "source": [
    "## Load cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db61f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"../data/rh_mod_v1.csv\"\n",
    "perform_text_cleaning = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00132c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_prep.prepare_data(filepath=path_to_data, clean_text=perform_text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6b46df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939afb26",
   "metadata": {},
   "source": [
    "## 3-2.1 - Analysing the effect of our decisions on reliability measures  <a class=\"anchor\" id=\"3-2.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3a7a5f",
   "metadata": {},
   "source": [
    "In this section, we will investigate how the thresholds we set impact the semi-automated reliability meaures we extract from our maintenance work order data.\n",
    "\n",
    "To make this process interactive, what we developed in the previous notebook (*W3-1 Data-Driven Reliability Metrics*) has been wrapped into the function `get_measures`. This function allows us to pass in information and observe the output of fitting our data to the 2-parameter Weibull distribution. The controllable parameters of this function include:\n",
    "- end-of-life terms (`eol_terms`), \n",
    "- minimum amount of failure/suspension evidence (`min_evidence_points`),\n",
    "- minimum total actual cost threshold (`cost_threshold`), and\n",
    "- any given functional location (optional; `functional_loc`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecff6add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_measures(\n",
    "    df: pd.DataFrame,\n",
    "    eol_terms: list,\n",
    "    fs_col_name: str = \"wo_order_type\",\n",
    "    fs_col_fail_values: list = [\"PM01\"],\n",
    "    fs_col_suspension_values: list = [\"PM02\"],\n",
    "    min_evidence_points: int = 5,\n",
    "    cost_threshold: int = 2000,\n",
    "    functional_loc: str = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Function for dynamically calculating reliability measures using expert logic and the Reliability package\n",
    "\n",
    "    Arguments\n",
    "        df : a Pandas DataFrame containing maintenance work order data (cleaned or not cleaned)\n",
    "        eol_terms : a list of terms indicating end-of-life events\n",
    "        fs_col_name : the name of the column in the supplied DataFrame that can be used to classify end-of-life events as failure or suspension\n",
    "        fs_col_fail_values : a list of values that will be matched to indicate a failure event\n",
    "        fs_col_suspension_values : a list of values that will be matched to indicate a suspension event\n",
    "        min_evidence_points : an integer that indicates the minimum expected failure/suspension evidence required\n",
    "        cost_threshold : an integer indicating the minimum cost a record with an EOL identified must have to be considered\n",
    "        functional_loc : a string containing a valid functional location. If this is not supplied, all functional locations will be processed\n",
    "\n",
    "    Returns\n",
    "        - df_results_with_objs : Pandas DataFrame with Weibull values for each functional location\n",
    "        - df_filtered : Pandas DataFrame with original data filtered and classified\n",
    "    \"\"\"\n",
    "\n",
    "    expected_cols = [\n",
    "        \"description\",\n",
    "        \"total_actual_costs\",\n",
    "        \"functional_loc\",\n",
    "        \"actual_start_date\",\n",
    "    ]\n",
    "\n",
    "    assert set(expected_cols).issubset(\n",
    "        set(df.columns)\n",
    "    ), \"Data provided to function does not have all the expected columns\"\n",
    "\n",
    "    if functional_loc != None:\n",
    "        df = df[df[\"functional_loc\"] == functional_loc]\n",
    "\n",
    "    # Make small dataframe containing object descriptions to join onto results\n",
    "    df_obj_desc = df[[\"functional_loc\", \"object_desc\"]].drop_duplicates()\n",
    "\n",
    "    # Perform preliminary filtering of\n",
    "    # - functional locations with # records below min_evidence_points\n",
    "\n",
    "    counts = df[\"functional_loc\"].value_counts()\n",
    "    idx = counts[counts <= min_evidence_points]\n",
    "    df_filtered = df[~df[\"functional_loc\"].isin(idx)]\n",
    "\n",
    "    # Create pattern for matching\n",
    "    eol_search_pattern = \"|\".join(eol_terms)\n",
    "\n",
    "    # Perform EOL identification\n",
    "    df_filtered[\"eol\"] = df_filtered[\"description\"].str.contains(\n",
    "        eol_search_pattern, case=False\n",
    "    )\n",
    "\n",
    "    # Keep only EOL rows\n",
    "    df_filtered = df_filtered[df_filtered[\"eol\"]]\n",
    "\n",
    "    # Perform EOL classification\n",
    "    df_filtered[\"fs_clf\"] = np.where(\n",
    "        (df_filtered[fs_col_name].isin(fs_col_suspension_values)),\n",
    "        \"suspension\",\n",
    "        np.where(df_filtered[fs_col_name].isin(fs_col_fail_values), \"failure\", \"other\"),\n",
    "    )\n",
    "\n",
    "    # Filter data on threshold\n",
    "    df_filtered = df_filtered[(cost_threshold <= df_filtered[\"total_actual_costs\"])]\n",
    "\n",
    "    # Groupby functional_loc to get failure/suspension data for reliability measure estimations\n",
    "    fs_data_per_group = {}\n",
    "    for name, values in df_filtered.groupby([\"functional_loc\"]):\n",
    "        if len(values) < min_evidence_points:\n",
    "            continue\n",
    "        else:\n",
    "            values = values[[\"actual_start_date\", \"fs_clf\"]]\n",
    "            # Lets sort the groups data by actual_start_date so that the earliest come first\n",
    "            fs_data = values.sort_values(by=[\"actual_start_date\"], ascending=True)\n",
    "\n",
    "            # Calculate the time between event (we'll use days here)\n",
    "            fs_data[\"time\"] = fs_data[\"actual_start_date\"].diff() / np.timedelta64(\n",
    "                1, \"D\"\n",
    "            )\n",
    "            fs_data[\"time\"] = fs_data[\"time\"].fillna(0)\n",
    "\n",
    "            # Encode failures and suspensions as 1 and 0, respectively\n",
    "            fs_data[\"fs_clf\"].replace(to_replace=\"failure\", value=1, inplace=True)\n",
    "            fs_data[\"fs_clf\"].replace(to_replace=\"suspension\", value=0, inplace=True)\n",
    "\n",
    "            fs_data_per_group[name] = fs_data[[\"fs_clf\", \"time\"]]\n",
    "\n",
    "    # Get reliability measures from fitting to 2P Weibull distribution\n",
    "    results_per_group = {}\n",
    "    for name, fs_data in fs_data_per_group.items():\n",
    "\n",
    "        num_evidence = len(fs_data)\n",
    "\n",
    "        if num_evidence < min_evidence_points:\n",
    "            pass\n",
    "        else:\n",
    "            fs_data = fs_data[\n",
    "                0 < fs_data[\"time\"]\n",
    "            ]  # Do not take into account any events that have 0 time\n",
    "\n",
    "            failures = fs_data[fs_data[\"fs_clf\"] == 1]\n",
    "            right_censored = fs_data[fs_data[\"fs_clf\"] == 0]  # suspensions\n",
    "\n",
    "            failure_times = failures[\"time\"].tolist()\n",
    "            right_censored_times = right_censored[\"time\"].tolist()\n",
    "\n",
    "            try:\n",
    "\n",
    "                if 1 < len(failures):\n",
    "                    wbfit = Fit_Weibull_2P(\n",
    "                        failures=failure_times,\n",
    "                        right_censored=right_censored_times\n",
    "                        if len(right_censored_times) > 0\n",
    "                        else None,\n",
    "                        show_probability_plot=False,\n",
    "                        print_results=False,\n",
    "                    )\n",
    "                    results_per_group[name] = {\n",
    "                        \"alpha\": wbfit.alpha,\n",
    "                        \"beta\": wbfit.beta,\n",
    "                        \"mean\": wbfit.distribution.mean,\n",
    "                        \"time_on_test\": fs_data[\"time\"].sum(),\n",
    "                        \"evidence\": num_evidence,\n",
    "                    }\n",
    "            except:\n",
    "                # TODO: handle exceptions with fs data\n",
    "                pass\n",
    "\n",
    "    # Join object descriptions onto dataframe for visualisation\n",
    "    df_results = pd.DataFrame.from_dict(results_per_group).T\n",
    "    df_results = df_results.rename_axis(\"functional_loc\").reset_index()\n",
    "    df_results_with_objs = pd.merge(\n",
    "        df_results, df_obj_desc, on=\"functional_loc\", how=\"left\"\n",
    "    )\n",
    "\n",
    "    df_results_with_objs = df_results_with_objs.round(\n",
    "        {\"alpha\": 0, \"beta\": 1, \"mean\": 0}\n",
    "    )\n",
    "\n",
    "    # We will filter out output df_filtered for only the FLOCs that have results\n",
    "    df_filtered = df_filtered[\n",
    "        df_filtered[\"functional_loc\"].isin(\n",
    "            df_results_with_objs[\"functional_loc\"].unique().tolist()\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return df_results_with_objs, df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1573b1",
   "metadata": {},
   "source": [
    "In the function `get_measures`, we can load in a set of end-of-life terms. Recall in the previous notebook, we elicited a set of terms using word embeddings and saved them. If you don't have these, that is okay, but if you do, the following code snippet will load them into this notebook and allow us to use them throughout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5e2b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eol_file_path = \"../data/eol_terms.txt\"\n",
    "\n",
    "eol_file = Path(eol_file_path)\n",
    "if eol_file.is_file():\n",
    "    print(\"File found - loading terms\")\n",
    "    with open(eol_file, \"r\", encoding=\"utf-8\") as infile:\n",
    "        eol_terms = infile.readlines()\n",
    "        eol_terms = [\n",
    "            term.replace(\"\\n\", \"\") for term in eol_terms\n",
    "        ]  # Remove new line separator\n",
    "\n",
    "    print(f\"Loaded {len(eol_terms)} terms\")\n",
    "else:\n",
    "    print(\"No file found - using default terms\")\n",
    "    eol_terms = [\n",
    "        \"replace\",\n",
    "        \"change out\",\n",
    "        \"c/o\",\n",
    "        \"seized\",\n",
    "        \"blown\",\n",
    "        \"failed\",\n",
    "        \"failure\",\n",
    "        \"collapsed\",\n",
    "        \"holed\",\n",
    "        \"unserviceable\",\n",
    "        \"u/s\",\n",
    "        \"replacement\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d06f179",
   "metadata": {},
   "source": [
    "Let's take a look at what our aggregate function is outputting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d6583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets run the function on our data\n",
    "df_test_results, df_test_clf = get_measures(\n",
    "    df=df,\n",
    "    eol_terms=eol_terms,\n",
    "    fs_col_name=\"wo_order_type\",\n",
    "    fs_col_fail_values=[\"PM01\"],\n",
    "    fs_col_suspension_values=[\"PM02\"],\n",
    "    min_evidence_points=5,\n",
    "    cost_threshold=10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5678fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output results includes Weibull parameters and other meta data\n",
    "df_test_results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99057b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output classifications include classifications for EOL identification and failure suspension\n",
    "df_test_clf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0e197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also get the results for a single floc if you desire\n",
    "df_test_results_single_floc, df_test_clf_single_floc = get_measures(\n",
    "    df=df,\n",
    "    eol_terms=eol_terms,\n",
    "    fs_col_name=\"wo_order_type\",\n",
    "    fs_col_fail_values=[\"PM01\"],\n",
    "    fs_col_suspension_values=[\"PM02\"],\n",
    "    min_evidence_points=5,\n",
    "    cost_threshold=10000,\n",
    "    functional_loc=\"1071-30-05-01-CVR123-STRC-CHU002\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffad1956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look at the 2P Weibull parameter data\n",
    "df_test_results_single_floc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb463647",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lets look at the data used to get the 2P Weibull parameters\n",
    "df_test_clf_single_floc[\n",
    "    [\n",
    "        \"functional_loc\",\n",
    "        \"description\",\n",
    "        \"total_actual_costs\",\n",
    "        \"actual_start_date\",\n",
    "        \"eol\",\n",
    "        \"fs_clf\",\n",
    "    ]\n",
    "].sort_values(by=\"actual_start_date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfff5952",
   "metadata": {},
   "source": [
    "Recall in the previous notebook we set our thresholds to a single values that was applied across all our assets. Obviously, this is not ideal nor representative as the cost of a pump change out is different to that of a gearbox. As indicated in the previous notebook, you could perform an analysis per functional location and update the notebook to account for specific thresholds for each asset type or functional location.\n",
    "\n",
    "However, what we are going to do here is perform an exploratory visual analysis of our data using an interactive package called [Bokeh Panel](https://panel.holoviz.org/reference/panes/Bokeh.html) and [Plotly](https://plotly.com/python/). If you're familiar with Business Intelligence tools, it will give you the same feel as we'll be creating a small dashboard inside our notebook! This ability to go from raw data all the way to visualisation is seamless in Python, unlike other ardouous workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcb4f1a",
   "metadata": {},
   "source": [
    "The code snippet below is a small dashboard/visualisation on top of our `get_measures` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59267c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up our interactive application\n",
    "min_evidence = pnw.IntSlider(name=\"minimum evidence\", value=10, start=1, end=25, step=1)\n",
    "cost_threshold = pnw.IntSlider(\n",
    "    name=\"cost threshold\", value=10000, start=0, end=100000, step=2500\n",
    ")\n",
    "\n",
    "\n",
    "def mpl_plot(data):\n",
    "    fig = px.scatter(\n",
    "        data,\n",
    "        x=\"alpha\",\n",
    "        y=\"beta\",\n",
    "        size=\"evidence\",\n",
    "        color=\"mean\",\n",
    "        symbol=\"object_desc\",\n",
    "        color_continuous_scale=\"Bluered_r\",\n",
    "        custom_data=[\"mean\", \"evidence\", \"object_desc\", \"functional_loc\"],\n",
    "    )\n",
    "\n",
    "    fig.update_traces(\n",
    "        hovertemplate=\"<br>\".join(\n",
    "            [\n",
    "                \"Alpha: %{x}\",\n",
    "                \"Beta: %{y}\",\n",
    "                \"Mean: %{customdata[0]}\",\n",
    "                \"Evidence: %{customdata[1]}\",\n",
    "                \"Object: %{customdata[2]}\",\n",
    "                \"FLOC: %{customdata[3]}\",\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig = fig.update_layout(title_text=f\"Overview of Results ({len(data)} assets)\")\n",
    "    fig = fig.update_layout(coloraxis_colorbar=dict(orientation=\"h\"))\n",
    "    return fig\n",
    "\n",
    "\n",
    "def show_measures(min_evidence_points=5, cost_threshold=25000, view_fn=mpl_plot):\n",
    "    df_test_interactive, df_test_clfs = get_measures(\n",
    "        df=df,\n",
    "        eol_terms=eol_terms,\n",
    "        fs_col_name=\"wo_order_type\",\n",
    "        fs_col_fail_values=[\"PM01\"],\n",
    "        fs_col_suspension_values=[\"PM02\"],\n",
    "        min_evidence_points=min_evidence_points,\n",
    "        cost_threshold=cost_threshold,\n",
    "    )\n",
    "\n",
    "    return view_fn(data=df_test_interactive)\n",
    "\n",
    "\n",
    "@pn.depends(min_evidence, cost_threshold)\n",
    "def reactive_measures(min_evidence, cost_threshold):\n",
    "    return show_measures(\n",
    "        min_evidence_points=min_evidence, cost_threshold=cost_threshold\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1a1098",
   "metadata": {},
   "source": [
    "Lets run the application and explore our results.\n",
    "\n",
    "‚ö†Ô∏è Please be aware that every time you interact with the sliders, it will recompute EVERY Weibull estimate for each applicable asset. So please be patient between updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa33e1c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "settings = pn.Row(pn.Column(min_evidence, cost_threshold))\n",
    "\n",
    "app = pn.Column(settings, reactive_measures)\n",
    "app.servable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099b6205",
   "metadata": {},
   "source": [
    "Through the use of interactive visualisation using Bokeh and Plotly we can easily get an intuition for the mean values of a range of assets. For instance, if we set the thresholds very low, we are likely to capture evidence that may not be correct, however as we increase the thresholds our belief in evidence being correct also goes up.\n",
    "\n",
    "Hence, we can get a feel for the range of mean time estimates on a given asset through this minima/maxima analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e211d5e",
   "metadata": {},
   "source": [
    "### Looking closer at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c614a8",
   "metadata": {},
   "source": [
    "Its apparent that some of the functional locations are displaying interesting behaviour. It would be useful if we could look at each functional location individually to better understand what is happening and improve our understanding. Lets use Bokeh and Plotly to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41a5197",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_evidence_2 = pn.widgets.DiscreteSlider(\n",
    "    name=\"minimum evidence\", options=list(range(0, 25, 1)), value=10\n",
    ")\n",
    "cost_threshold_2 = pn.widgets.DiscreteSlider(\n",
    "    name=\"cost threshold\", value=10000, options=list(range(0, 100000, 2500))\n",
    ")\n",
    "\n",
    "\n",
    "def mpl_plot(data):\n",
    "    fig = px.scatter(\n",
    "        data,\n",
    "        x=\"alpha\",\n",
    "        y=\"beta\",\n",
    "        size=\"evidence\",\n",
    "        color=\"mean\",\n",
    "        symbol=\"object_desc\",\n",
    "        color_continuous_scale=\"Bluered_r\",\n",
    "        custom_data=[\"mean\", \"evidence\", \"object_desc\", \"functional_loc\"],\n",
    "    )\n",
    "\n",
    "    fig.update_traces(\n",
    "        hovertemplate=\"<br>\".join(\n",
    "            [\n",
    "                \"Alpha: %{x}\",\n",
    "                \"Beta: %{y}\",\n",
    "                \"Mean: %{customdata[0]}\",\n",
    "                \"Evidence: %{customdata[1]}\",\n",
    "                \"Object: %{customdata[2]}\",\n",
    "                \"FLOC: %{customdata[3]}\",\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig = fig.update_layout(title_text=f\"Overview of Results ({len(data)} assets)\")\n",
    "    fig = fig.update_layout(coloraxis_colorbar=dict(orientation=\"h\"))\n",
    "    return fig\n",
    "\n",
    "\n",
    "def reactive_dataframe(data):\n",
    "    # Creating the list of columns:\n",
    "    columns = [\n",
    "        TableColumn(field=\"functional_loc\", title=\"Functional Loc\"),\n",
    "        TableColumn(field=\"object_desc\", title=\"Object Desc\"),\n",
    "        TableColumn(field=\"description\", title=\"Description\"),\n",
    "        TableColumn(field=\"eol\", title=\"Is EOL?\"),\n",
    "        TableColumn(field=\"total_actual_costs\", title=\"Total Actual Costs\"),\n",
    "        TableColumn(field=\"fs_clf\", title=\"FS Classification\"),\n",
    "    ]\n",
    "    # Initializing the table:\n",
    "    source = ColumnDataSource(data)\n",
    "    table = DataTable(source=source, columns=columns, width=800, height=200)\n",
    "    return table\n",
    "\n",
    "\n",
    "def get_data(min_evidence, cost_threshold):\n",
    "    df_test_interactive, df_test_clfs = get_measures(\n",
    "        df=df,\n",
    "        eol_terms=eol_terms,\n",
    "        fs_col_name=\"wo_order_type\",\n",
    "        fs_col_fail_values=[\"PM01\"],\n",
    "        fs_col_suspension_values=[\"PM02\"],\n",
    "        min_evidence_points=min_evidence,\n",
    "        cost_threshold=cost_threshold,\n",
    "    )\n",
    "    return df_test_interactive, df_test_clfs\n",
    "\n",
    "\n",
    "layout = pn.Column(\n",
    "    pn.Row(\"### Interactive Visualisation\"),\n",
    "    pn.Row(min_evidence_2, cost_threshold_2),\n",
    "    pn.Row(\n",
    "        reactive_dataframe(\n",
    "            data=get_data(min_evidence_2.value, cost_threshold_2.value)[1]\n",
    "        )\n",
    "    ),\n",
    "    pn.Row(mpl_plot(data=get_data(min_evidence_2.value, cost_threshold_2.value)[0])),\n",
    "    sizing_mode=\"stretch_both\",\n",
    ")\n",
    "\n",
    "\n",
    "def update(event):\n",
    "    # Update data\n",
    "    data, data_clf = get_data(min_evidence_2.value, cost_threshold_2.value)\n",
    "    layout[3][0].object = mpl_plot(data=data)\n",
    "    layout[2][0].object = reactive_dataframe(data=data_clf)\n",
    "\n",
    "\n",
    "min_evidence_2.param.watch(update, \"value\")\n",
    "cost_threshold_2.param.watch(update, \"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6991b465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the dashboard/application\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eb6379",
   "metadata": {},
   "source": [
    "## 3-2.2 - Additional Analysis<a class=\"anchor\" id=\"3-2.2\"></a>\n",
    "In this section we'll use our Python programming skills to perform additional analysis on our maintenance work order dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774195bd",
   "metadata": {},
   "source": [
    "Before we do this, we'll create a dataframe containing the results of our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd37797",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_cost_threshold = 10000\n",
    "analysis_min_evidence = 10\n",
    "analysis_eol_terms = eol_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d861702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis_results, df_analysis_filtered = get_measures(\n",
    "    df=df,\n",
    "    eol_terms=analysis_eol_terms,\n",
    "    fs_col_name=\"wo_order_type\",\n",
    "    fs_col_fail_values=[\"PM01\"],\n",
    "    fs_col_suspension_values=[\"PM02\"],\n",
    "    min_evidence_points=analysis_min_evidence,\n",
    "    cost_threshold=analysis_cost_threshold,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2406d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a look at the data we are working with\n",
    "df_analysis_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7ac905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by mean value\n",
    "df_analysis_results.sort_values(by=[\"mean\"], inplace=True, ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a779edaf",
   "metadata": {},
   "source": [
    "### Find the Top 10 Bad Actors\n",
    "Here we'll identify the top 10 bad actors in terms of their mean time values (lower value is worse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c06f912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 bad actors based on FLOC\n",
    "top_10_bad_actors_floc = df_analysis_results[:10]\n",
    "top_10_bad_actors_floc.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a32407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let get the FLOC associated with the worst actor\n",
    "worst_actor_floc = top_10_bad_actors_floc.iloc[0][\"functional_loc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fdc470",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lets take a look at the records associated with the functional location\n",
    "df_analysis_filtered_floc = df_analysis_filtered[\n",
    "    df_analysis_filtered[\"functional_loc\"] == worst_actor_floc\n",
    "].sort_values(by=[\"eol\"], ascending=False)\n",
    "df_analysis_filtered_floc[[\"description\", \"total_actual_costs\", \"eol\", \"fs_clf\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ef0fa9",
   "metadata": {},
   "source": [
    "### Failure behavior classification\n",
    "Here we'll use the alpha and beta values from our analysis to classify all of the applicable assets. Recall that $\\beta$ < 1 is early life failures (infant mortality), $\\beta$ = 1 is random failures, and $\\beta$ > 1 is wear out failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec916fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis_results_fail_clf = df_analysis_results.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aea9d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis_results_fail_clf[\"behaviour\"] = np.where(\n",
    "    df_analysis_results_fail_clf[\"beta\"] < 1,\n",
    "    \"early_life\",\n",
    "    np.where(df_analysis_results_fail_clf[\"beta\"] == 1, \"random\", \"wear_out\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae1ea51",
   "metadata": {},
   "source": [
    "Lets visualise the failure behaviour / Weibull shape parameter of our assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4381f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    df_analysis_results_fail_clf,\n",
    "    x=\"functional_loc\",\n",
    "    y=\"mean\",\n",
    "    color=\"behaviour\",\n",
    "    title=\"Analysis of Weibull shape parameter\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f38f3b",
   "metadata": {},
   "source": [
    "## Wrap up & homework <a class=\"anchor\" id=\"wrap-up\"></a>\n",
    "Homework for next week\n",
    "1. Complete the coding activities in W3-1\n",
    "\n",
    "Your feedback today is welcome. Provide your answers in [Menti](https://www.menti.com/qusszgb46q): \n",
    "- What is one thing you liked about today?\n",
    "- What would you like to see more of?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "2a2ccc53c67f62631b8d9a249097e4dbd32cc773acbcb6419524310ebb9f7f1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
